server:
  port: 8080

ai:
  openai:
    deepseek-v3:
      base-url: https://chatapi.littlewheat.com
      api-key: sk-YiB76FYEBysWcTUw69FEGVfwqMzf1iKMILvobZg3ALVHFl63
      model: deepseek-v3-0324
      modelType: llm
      temperature: 0.7
      embeddingDimensions: 1024
      modelDescription: "Grok-3是xAI开发的最新一代大语言模型，具有强大的推理和创作能力"
      modelTag: "推理,创作,多模态"
    bge-m3:
      base-url: https://chatapi.littlewheat.com
      api-key: sk-YiB76FYEBysWcTUw69FEGVfwqMzf1iKMILvobZg3ALVHFl63
      model: bge-m3
      model-type: embedding
      temperature: 0.5
      embeddingDimensions: 1024
      modelDescription: "OpenAI GPT-4o是最新的多模态大语言模型，支持文本、图像和音频处理"
      modelTag: "多模态,文本生成,图像理解,音频处理"

  ollama:
    deepseek:
      base-url: http://localhost:11434
      model: deepseek-r1:1.5B
      temperature: 0.7
      modelDescription: "DeepSeek-R1是一个专注于推理的大语言模型，在数学和逻辑推理方面表现优异"
      modelTag: "推理,数学,逻辑,编程"
    qwen:
      base-url: http://localhost:11434
      model: qwen3:1.7B
      temperature: 0.7
      modelDescription: "DeepSeek-R1是一个专注于推理的大语言模型，在数学和逻辑推理方面表现优异"
      modelTag: "推理,数学,逻辑,编程"

spring:
  autoconfigure:
    exclude:
      - org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration
      - org.springframework.ai.model.openai.autoconfigure.OpenAiAudioSpeechAutoConfiguration
  application:
    name: metaloom-ai
  main:
    allow-bean-definition-overriding: true
    banner-mode: off
  servlet:
    multipart:
      max-file-size: 50MB
      max-request-size: 100MB
  ai:
    chat:
      client:
        enabled: false # false的情况下禁止自动装配，就可以创建多个ChatClient了
    # OpenAI配置 - 使用text-embedding-3-large嵌入模型
    openai:
      api-key: sk-YiB76FYEBysWcTUw69FEGVfwqMzf1iKMILvobZg3ALVHFl63
      base-url: https://chatapi.littlewheat.com
      embedding:
        options:
          model: text-embedding-3-large
    ollama:
      base-url: "http://disabled-placeholder:11434"
    mcp:
      client:
        enabled: true
        # SSE 连接配置（连接到MCP Server）
        sse:
          connections:
            asset: # MCP服务端连接名称
              url: http://127.0.0.1:10001
              sse-endpoint: http://127.0.0.1:10001/sse  # MCP Server端的SSE端点
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    jdbc-url: jdbc:mysql://192.168.43.241:3306/metaloom?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true
    username: root
    password: root
    hikari:
      minimum-idle: 5
      maximum-pool-size: 20
      auto-commit: true
      idle-timeout: 30000
      pool-name: HikariCP
      max-lifetime: 1800000
      connection-timeout: 30000
      connection-test-query: SELECT 1

mybatis-plus:
  configuration:
    map-underscore-to-camel-case: true
    cache-enabled: false
    call-setters-on-nulls: true
    jdbc-type-for-null: 'null'
  global-config:
    db-config:
      id-type: auto
      logic-delete-field: deleted
      logic-delete-value: 1
      logic-not-delete-value: 0
  mapper-locations: classpath*:mapper/**/*.xml
  type-aliases-package: com.metaloom.common.jdbc

# A2A智能体配置
metaloom:
  a2a:
    enabled: true
    max-iterations: 5
    timeout: 30000
    available-agents:
      - lineage_agent
      - metadata_agent
    agents:
      lineage_agent:
        name: "血缘分析智能体"
        description: "用于查询数据血缘关系、数据流向、依赖关系等"
        enabled: true
        timeout: 10000
      metadata_agent:
        name: "元数据查询智能体"
        description: "用于查询表结构、字段信息、数据字典等元数据信息"
        enabled: true
        timeout: 10000
    llm:
      provider: "openai"
      model: "deepseek-v3"
      temperature: 0.7
      max-tokens: 2000
      system-prompt: |
        你是一个数据分析智能体协调器。你的任务是分析用户查询，并决定调用哪个专家智能体来获取信息。
        
        可用的专家智能体：
        1. 血缘分析智能体 (lineage_agent) - 用于查询数据血缘关系、数据流向、依赖关系等
        2. 元数据查询智能体 (metadata_agent) - 用于查询表结构、字段信息、数据字典等元数据信息
        
        响应格式要求：
        请严格按照以下JSON格式响应：
        {
            "action_type": "call_agent|final_answer",
            "agent_name": "lineage_agent|metadata_agent",
            "request_body": {
                "query": "具体的查询内容"
            },
            "reasoning": "解释为什么选择这个行动"
        }
        
        决策规则：
        - 如果查询涉及数据流向、血缘关系、依赖关系，调用lineage_agent
        - 如果查询涉及表结构、字段信息、数据字典，调用metadata_agent
        - 如果已经有足够信息可以回答用户问题，使用final_answer
        - 如果无法确定，优先调用metadata_agent获取基础信息
